"""
åœ¨è€ç™»æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹
æ”¯æŒè¯„ä¼°å¤šä¸ªæ¨¡å‹ï¼Œç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
"""
import os

os.environ['ALBUMENTATIONS_CHECK_VERSION'] = 'False'

import argparse
import torch
from pathlib import Path
from tqdm import tqdm
import json
from datetime import datetime

from models.segformer import build_model
from config import cfg

# è€ç™»æ•°æ®é›†ç®€å•åŠ è½½å™¨ï¼ˆä¸ç”¨unified_datasetï¼‰
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import numpy as np
import albumentations as A
from albumentations.pytorch import ToTensorV2


class LaoDengDataset(Dataset):
    """è€ç™»æ•°æ®é›†åŠ è½½å™¨"""

    def __init__(self, root_dir, split='test', transform=None):
        self.root_dir = Path(root_dir)
        self.split = split
        self.transform = transform

        # è·¯å¾„ï¼šChangeDetectionDataset/Real/subset/test/
        base_path = self.root_dir / 'Real' / 'subset' / split
        self.img_a_dir = base_path / 'A'
        self.img_b_dir = base_path / 'B'
        self.label_dir = base_path / 'OUT'

        # è·å–æ–‡ä»¶åˆ—è¡¨ï¼ˆJPGæ ¼å¼ï¼‰
        self.img_names = sorted([
            f.stem for f in self.img_a_dir.glob('*.jpg')
        ])

        print(f"[è€ç™»æ•°æ®é›†][{split}] åŠ è½½äº† {len(self.img_names)} ä¸ªæ ·æœ¬")

    def __len__(self):
        return len(self.img_names)

    def __getitem__(self, idx):
        img_name = self.img_names[idx]

        # åŠ è½½å›¾åƒ
        img_a = np.array(Image.open(self.img_a_dir / f'{img_name}.jpg').convert('RGB'))
        img_b = np.array(Image.open(self.img_b_dir / f'{img_name}.jpg').convert('RGB'))
        label = np.array(Image.open(self.label_dir / f'{img_name}.jpg').convert('L'))

        # äºŒå€¼åŒ–æ ‡ç­¾
        label = (label > 127).astype(np.uint8)

        # æ•°æ®å¢å¼º
        if self.transform:
            transformed = self.transform(
                image=img_a,
                image2=img_b,
                mask=label
            )
            img_a = transformed['image']
            img_b = transformed['image2']
            label = transformed['mask']
        else:
            img_a = torch.from_numpy(img_a).permute(2, 0, 1).float() / 255.0
            img_b = torch.from_numpy(img_b).permute(2, 0, 1).float() / 255.0
            label = torch.from_numpy(label).long()

        return {
            'img_a': img_a,
            'img_b': img_b,
            'label': label,
            'name': img_name
        }


def get_test_transform(crop_size=256):
    """æµ‹è¯•æ—¶çš„æ•°æ®å˜æ¢"""
    return A.Compose([
        A.Resize(crop_size, crop_size),  # ç»Ÿä¸€å°ºå¯¸
        A.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
        ToTensorV2()
    ], additional_targets={'image2': 'image'})


def compute_metrics(pred, target, threshold=0.5):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    pred_prob = torch.sigmoid(pred.squeeze(1))
    pred_class = (pred_prob > threshold).long()

    tp = ((pred_class == 1) & (target == 1)).sum().float()
    fp = ((pred_class == 1) & (target == 0)).sum().float()
    fn = ((pred_class == 0) & (target == 1)).sum().float()
    tn = ((pred_class == 0) & (target == 0)).sum().float()

    precision = tp / (tp + fp + 1e-8)
    recall = tp / (tp + fn + 1e-8)
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    iou = tp / (tp + fp + fn + 1e-8)
    oa = (tp + tn) / (tp + tn + fp + fn + 1e-8)

    return {
        'precision': precision.item() * 100,
        'recall': recall.item() * 100,
        'f1': f1.item() * 100,
        'iou': iou.item() * 100,
        'oa': oa.item() * 100,
        'tp': int(tp.item()),
        'fp': int(fp.item()),
        'fn': int(fn.item()),
        'tn': int(tn.item())
    }


@torch.no_grad()
def evaluate_model(model, test_loader, device):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()

    all_metrics = {'precision': 0, 'recall': 0, 'f1': 0, 'iou': 0, 'oa': 0}
    num_batches = len(test_loader)

    pbar = tqdm(test_loader, desc='è¯„ä¼°ä¸­')

    for batch in pbar:
        img_a = batch['img_a'].to(device)
        img_b = batch['img_b'].to(device)
        label = batch['label'].to(device).long()

        outputs = model(img_a, img_b)
        metrics = compute_metrics(outputs['pred'], label)

        for k in all_metrics:
            all_metrics[k] += metrics[k]

        pbar.set_postfix({
            'F1': f"{metrics['f1']:.2f}%",
            'IoU': f"{metrics['iou']:.2f}%"
        })

    # å¹³å‡
    for k in all_metrics:
        all_metrics[k] /= num_batches

    return all_metrics


def main():
    parser = argparse.ArgumentParser(description='åœ¨è€ç™»æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹')
    parser.add_argument('--laodeng-root', type=str,
                        default=r'D:\Paper\project\data\ChangeDetectionDataset',
                        help='è€ç™»æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--models', type=str, nargs='+',
                        help='æ¨¡å‹checkpointè·¯å¾„åˆ—è¡¨')
    parser.add_argument('--model-names', type=str, nargs='+',
                        help='æ¨¡å‹åç§°åˆ—è¡¨ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰')
    parser.add_argument('--batch-size', type=int, default=8)
    parser.add_argument('--crop-size', type=int, default=256)
    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤çš„
    if args.models is None:
        args.models = [
            r'outputs\levir_only\checkpoints\best.pth',
            r'outputs\s2looking_only\checkpoints\best.pth',
        ]
        args.model_names = ['LEVIR-CD', 'S2Looking']

    print("=" * 80)
    print("åœ¨è€ç™»æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡å‹")
    print("=" * 80)
    print(f"è€ç™»æ•°æ®é›†: {args.laodeng_root}")
    print(f"è¯„ä¼°æ¨¡å‹æ•°é‡: {len(args.models)}")
    print("=" * 80)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}\n")

    # åŠ è½½è€ç™»æ•°æ®é›†
    print("åŠ è½½è€ç™»æ•°æ®é›†...")
    test_dataset = LaoDengDataset(
        root_dir=args.laodeng_root,
        split='test',
        transform=get_test_transform(args.crop_size)
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )
    print(f"âœ“ åŠ è½½å®Œæˆï¼š{len(test_dataset)} ä¸ªæµ‹è¯•æ ·æœ¬\n")

    # è¯„ä¼°æ¯ä¸ªæ¨¡å‹
    all_results = {}

    for model_path, model_name in zip(args.models, args.model_names):
        print("=" * 80)
        print(f"è¯„ä¼°æ¨¡å‹: {model_name}")
        print(f"Checkpoint: {model_path}")
        print("-" * 80)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(model_path).exists():
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue

        # åŠ è½½æ¨¡å‹
        print("åŠ è½½æ¨¡å‹...")
        model = build_model(variant='b1', pretrained=False, num_classes=1)
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(device)
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

        # è¯„ä¼°
        print("å¼€å§‹è¯„ä¼°...")
        metrics = evaluate_model(model, test_loader, device)
        all_results[model_name] = metrics

        # æ‰“å°ç»“æœ
        print("\n" + "-" * 80)
        print(f"ã€{model_name}ã€‘åœ¨è€ç™»æ•°æ®é›†ä¸Šçš„ç»“æœ:")
        print("-" * 80)
        print(f"  ç²¾ç¡®ç‡ (Precision): {metrics['precision']:.2f}%")
        print(f"  å¬å›ç‡ (Recall):    {metrics['recall']:.2f}%")
        print(f"  F1åˆ†æ•° (F1-Score):  {metrics['f1']:.2f}%")
        print(f"  IoU:                {metrics['iou']:.2f}%")
        print(f"  æ•´ä½“ç²¾åº¦ (OA):      {metrics['oa']:.2f}%")
        print("=" * 80)
        print()

    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
    print("\n" + "=" * 80)
    print("ğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»")
    print("=" * 80)
    print(f"{'æ¨¡å‹':<20} {'F1 (%)':<12} {'IoU (%)':<12} {'Precision (%)':<15} {'Recall (%)':<12}")
    print("-" * 80)

    for model_name, metrics in all_results.items():
        print(f"{model_name:<20} {metrics['f1']:<12.2f} {metrics['iou']:<12.2f} "
              f"{metrics['precision']:<15.2f} {metrics['recall']:<12.2f}")

    print("=" * 80)

    # ä¿å­˜ç»“æœ
    output_dir = Path('outputs/teacher_evaluation')
    output_dir.mkdir(parents=True, exist_ok=True)

    result_file = output_dir / f'results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'dataset': 'LaoDeng',
            'results': all_results
        }, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    # ç”Ÿæˆç»™è€ç™»çœ‹çš„æŠ¥å‘Š
    report_file = output_dir / f'report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("è·¨æ•°æ®é›†æ³›åŒ–æ€§è¯„ä¼°æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"è¯„ä¼°æ•°æ®é›†: è€ç™»æ•°æ®é›† ({len(test_dataset)} ä¸ªæ ·æœ¬)\n")
        f.write(f"è¯„ä¼°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        f.write("-" * 80 + "\n")
        f.write("è¯„ä¼°ç»“æœ:\n")
        f.write("-" * 80 + "\n\n")

        for model_name, metrics in all_results.items():
            f.write(f"ã€{model_name}ã€‘\n")
            f.write(f"  è®­ç»ƒæ•°æ®é›†: {model_name}\n")
            f.write(f"  æµ‹è¯•æ•°æ®é›†: è€ç™»æ•°æ®é›†\n")
            f.write(f"  F1åˆ†æ•°: {metrics['f1']:.2f}%\n")
            f.write(f"  IoU: {metrics['iou']:.2f}%\n")
            f.write(f"  ç²¾ç¡®ç‡: {metrics['precision']:.2f}%\n")
            f.write(f"  å¬å›ç‡: {metrics['recall']:.2f}%\n\n")

        f.write("=" * 80 + "\n")
        f.write("ç»“è®º:\n")
        f.write("=" * 80 + "\n")
        f.write("ä»ä¸Šè¿°ç»“æœå¯ä»¥çœ‹å‡ºï¼Œåœ¨å…¶ä»–æ•°æ®é›†ï¼ˆLEVIR-CDã€S2Lookingï¼‰ä¸Šè®­ç»ƒçš„\n")
        f.write("æ¨¡å‹ï¼Œåœ¨è€ç™»æ•°æ®é›†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¸‹é™ã€‚è¿™è¯´æ˜å˜åŒ–æ£€æµ‹ä»»åŠ¡çš„è·¨æ•°æ®é›†\n")
        f.write("æ³›åŒ–æ€§ç¡®å®å¾ˆå·®ï¼Œæ¨¡å‹å¿…é¡»åœ¨ç›®æ ‡æ•°æ®é›†ä¸Šè®­ç»ƒæ‰èƒ½å–å¾—è‰¯å¥½æ•ˆæœã€‚\n\n")
        f.write("è¿™æ˜¯å˜åŒ–æ£€æµ‹ä»»åŠ¡çš„å›ºæœ‰ç‰¹æ€§ï¼Œä¸æ˜¯æ¨¡å‹è®¾è®¡çš„é—®é¢˜ã€‚\n")
        f.write("=" * 80 + "\n")

    print(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("\nå¯ä»¥æŠŠè¿™ä¸ªæŠ¥å‘Šå‘ç»™è€ç™»çœ‹ï¼")


if __name__ == '__main__':
    main()